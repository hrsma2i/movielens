{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens 100K recommendation\n",
    "MovieLens 100K のデータセットに対し、 \n",
    "recommendation のアルゴリズムの1つ、 SVD\n",
    "を実装した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVDアルゴリズムの説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recommedation アルゴリズムの概要\n",
    "\n",
    "- 背景: 最近は情報過多社会。ユーザーにとって最適な商品（アイテム）の情報を探すのは大変。\n",
    "- 目的: そこで各ユーザーが好む最適な商品を、全ての商品から選出する必要がある。\n",
    "- 入力: ユーザーの行動履歴・評価 | アイテムの特徴 etc\n",
    "- 出力: ユーザーの評価が高い・買うであろうアイテム | 似たようなアイテム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recommedation アルゴリズムの分類\n",
    "\n",
    "- **CF Collaborative Filetering**\n",
    "    - memoery-based | Nearest Neighbor\n",
    "        - user-user | user-based\n",
    "        - item-item | item-based\n",
    "    - **model-based**\n",
    "        - **MF Matrix Factorization**\n",
    "            - SVD (only  explicit)\n",
    "            - SVD++ (also implicit)\n",
    "            - NMF\n",
    "        - clustering | regression | 確率モデル | topic model | Bayesean Network model | restricted Boltzmann machine | time series model\n",
    "- Content-based\n",
    "- Hybrid = CF + Content\n",
    "\n",
    "今回は、 CF > model-based > MF > SVD を実装した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF vs Content-based\n",
    "- **CF**\n",
    "    - 入力: あるユーザーによる 商品のrating, 商品の購買・閲覧履歴 (e.g. 購入した服の5段階☆評価、ある服のページの閲覧、購入入したかしないか）\n",
    "    - 出力: ユーザーの評価が高い・買うであろうアイテム (e.g. )\n",
    "- Content-based\n",
    "    - 入力: アイテムの特徴 (e.g. 服の画像) \n",
    "    - 出力: 似たようなアイテム (e.g. 見た目が似たような服)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memory-based vs model-based\n",
    "\n",
    "CF では、下のFig.1のような　**(ユーザー数) x (アイテム数) の形の user-item matrix** をデータとして扱う。\n",
    "\n",
    "![](https://i.imgur.com/bmW79NS.png)\n",
    "\n",
    "Fig.1: user-item matrix rating\n",
    "\n",
    "行がuser, 列がitem　を表し、\n",
    "行列の各要素が、ある user による、ある item の 評価値である。\n",
    "\n",
    "行列の要素は **1~5段階評価** などがよく使われるが、\n",
    "評価ではなく、そのitemページの閲覧や、そのitemの購入をしたかしないか\n",
    "の **バイナリ（0/1）** でもよい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### memory-based\n",
    "\n",
    "memory-based は、各行|列を user|item を表すベクトルとしてとらえる。\n",
    "そして、**ベクトル間の内積**などで、 user|item 間の類似度を計算し、\n",
    "特定の user に対し、オススメの item を recommend する。\n",
    "\n",
    "**user-based** だと、user ベクトルの類似度を計算し、\n",
    "推薦をしたい user A が、まだ購入していない item のうち、\n",
    "A と似ている user B, C が高評価しているアイテムを推薦する。\n",
    "\n",
    "**item-based** では、 item ベクトルの類似度を計算し、\n",
    "A が高評価している item と似ている item を推薦する。\n",
    "\n",
    "欠点:\n",
    "- user-item matrix は sparse (0ばかり) であることが多く、良い精度で recommend できない。\n",
    "- recommendation 時に毎回、類似度を計算しなくてはならないので、 recommedation に時間がかかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model-based\n",
    "\n",
    "user-item matrix をそのまま推薦に用いるのではなく、\n",
    "一度、 **統計モデル** を学習させてから、推薦する手法。\n",
    "\n",
    "memory-based の欠点に対応している。\n",
    "- user による評価値の推定 → sparse 性への対応\n",
    "- 学習に時間がかかるが、一度学習してしまえば、推薦時間は短い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "\n",
    "#### MF Matrix Factorization\n",
    "user-item matrix における各 user|item ベクトルを\n",
    "潜在的な特徴量での表現に変換し、欠損している評価値を推定する手法。\n",
    "\n",
    "具体的には、 user-item matrixの形が $U \\times I$ だとすると、\n",
    "各行 = user ベクトルの特徴量は、各 item の評価値 $r_i$ である。\n",
    "\n",
    "$\\boldsymbol{u} = (r_1, r_2, ..., r_I)$\n",
    "\n",
    "一方、各列 = item ベクトルの特徴量は、各 user の評価値 $r_u$ である。\n",
    "\n",
    "$\\boldsymbol{i} = (r_1, r_2, ..., r_U)$\n",
    "\n",
    "これらのベクトルを、$k$ （任意）次元の特徴量で表現する。\n",
    "\n",
    "$\\boldsymbol{u} = (f_1, f_2, ..., f_k)^T$\n",
    "\n",
    "$\\boldsymbol{i} = (g_1, g_2, ..., g_k)^T$\n",
    "\n",
    "これらを user|item ごとに並べた行列を\n",
    "\n",
    "- $P: K \\times U$\n",
    "- $Q: K \\times I$\n",
    "\n",
    "とし、それぞれ **user|item factor** と呼ぶことにする。\n",
    "そして、真の user-matrix（欠損値のない user-matrix）は、\n",
    "これらの積で表されると仮定する。\n",
    "すなわち、真の user-matrix の予測行列を、 $\\hat{R}$ とすると\n",
    "\n",
    "$\\hat{R} = P^TQ$\n",
    "\n",
    "となる。\n",
    "\n",
    "このような仮定を置く理由は、以下の直観的な背景からである。\n",
    "\n",
    "userおよびitemは、k個の潜在的な特徴量を持っていると考える。\n",
    "たとえば、\n",
    "\n",
    "- user ベクトルの視点: この user が SF をどれくらい好きかを表す数値\n",
    "- item ベクトルの視点: この movie がどれくらい、SFに当てはまるかの数値\n",
    "\n",
    "などが潜在的な特徴量として考えられる。\n",
    "\n",
    "userの好みのジャンルとitemのジャンルが近ければ、\n",
    "そのuserによる、そのitemの評価は高くなることが直観的に考えられる。\n",
    "\n",
    "また、userの潜在特徴ベクトルと、itemの潜在特徴ベクトルの内積は\n",
    "両ベクトルが似ているほど高い値を示す。\n",
    "つまり、先の、ジャンルと評価値の関係は、\n",
    "この潜在特徴ベクトルとその内積の値の関係ににている。\n",
    "なので、評価値は、各user、itemの潜在特徴ベクトルの内積で表せると仮定する。\n",
    "\n",
    "$r_{u,j} = \\boldsymbol{u}^T\\boldsymbol{i}$\n",
    "\n",
    "これを行列でまとめて表現すると、先ほどの仮定に一致する。\n",
    "\n",
    "$\\hat{R} = P^TQ$\n",
    "\n",
    "また、この仮定は、user-item matrix $R$ を\n",
    "2つの行列 $P, Q$ に分解しているので、行列分解 Matrix Factorizationとよぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD\n",
    "\n",
    "MF のアルゴリズムの代表の1つとして、\n",
    "**SVD Singular Value Decomposition** があり、\n",
    "今回はこれを実装した。\n",
    "\n",
    "user|item factor どうしの積 $P^TQ$ が、\n",
    "真の user-item matrix $R$ に近づけばいいので、\n",
    "これらの誤差を目的関数とする最小化問題を解けば良い。\n",
    "式で表すと、\n",
    "\n",
    "$\n",
    "min. \\sum_{u,i}(R-P^TQ)_{u,i}^2 \n",
    "+ \\lambda(\\|P\\|^2 + \\|Q\\|^2)\n",
    "$\n",
    "\n",
    "なお、学習パラメータは $P,Q$ であり、 \n",
    "$\\lambda$ は過学習を防ぐ正則化項の係数である。\n",
    "\n",
    "最適化手法として、今回は SGD Stochastic Gradient Descent を用いる。\n",
    "すなわち、上記の目的関数の勾配を用いて、パラメータ $P, Q$ を更新していく。\n",
    "更新式は以下。\n",
    "\n",
    "$\n",
    "e_{u,i} = (R-P^TQ)_{u,i}\\\\\n",
    "P_u \\leftarrow P_u - \\eta (- e_{u,i}Q_i + \\lambda P_u)\\\\\n",
    "Q_i \\leftarrow Q_i - \\eta (- e_{u,i}P_u + \\lambda Q_i)\n",
    "$\n",
    "\n",
    "$\\eta$ はlearning rateであり、後の括弧の中が目的関数の勾配である。\n",
    "\n",
    "注意として、与えられた user-item matrix において、\n",
    "**評価値の存在する user, item の組 $(u,i)$ のみ**について更新を行う。\n",
    "そうでないと、欠損値を0とすると、その0が未評価という意味ではなく、\n",
    "0という評価値として扱われ、良い精度が出ないためである。\n",
    "\n",
    "なお、すべての、 user, item の組 $(u,i)$ について iteration していき、\n",
    "1組の $(u,i)$ につき、$P_u, Q_i$ をそれぞれ1回 update してゆく。\n",
    "また、すべての組についての更新が終わったら、これを1epochとし、\n",
    "学習時の引数として、指定epoch回数、これを繰り返す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、今回は、学習パラメタに bias を追加した。\n",
    "\n",
    "$$\n",
    "\\hat{R} = P^TQ \n",
    "+ \\left[\n",
    "    \\begin{array}{rrr}\n",
    "        b_{u} & \n",
    "        b_{u} &\n",
    "        \\cdots &\n",
    "        b_{u}\n",
    "    \\end{array}\n",
    "\\right]\n",
    "+ \\left[\n",
    "    \\begin{array}{rrr}\n",
    "        b_{i} \\\\\n",
    "        b_{i} \\\\\n",
    "        \\vdots \\\\\n",
    "        b_{i}\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "で近似する。\n",
    "bias を導入することで、\n",
    "辛口|甘口 user や、大人気|不人気 item による評価の偏りを考慮できる。\n",
    "辛口でれば、user-bias のその user の要素は負の値をとり、\n",
    "その user の評価が全 item において低くなるように調整できる。\n",
    "\n",
    "上述の説明では、biasを加えると、SVDの本質がわかりにくくなるため、あえて省いた。\n",
    "目的関数も、勾配の式も、導出の方法は上述同様。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 評価\n",
    "MovieLensの trainting data u1.base、test data u1.test において、\n",
    "u1.baseで学習させ、u1.testで評価した。\n",
    "\n",
    "評価指標は直観的にわかりやすいRMSE, MAEを用いた。\n",
    "評価値が1であれば、各予測評価値が真の観測評価値よりも平均して1ほどずれている\n",
    "と考えればよい。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVDの改善点\n",
    "\n",
    "### explicit vs implicit data\n",
    "\n",
    "- **explicit data**: user に恣意的に行ってもらった rating\n",
    "    - e.g. 今回の movielens のような5段階で item を rating してもらったデータ\n",
    "    - 短所: user に rating してもらうので、 user に負担がかかり、データを集めにくい。 data を集められない → recommend できない → user が集まらない → data が集まらない → ... という悪循環に陥る可能性がある。 （cold-start problem)\n",
    "- **implicit data**\n",
    "    - e.g. 購入回数、動画の再生時間、ページ閲覧回数などの行動履歴\n",
    "    - 長所: 簡単に集められる。\n",
    "    - 短所: rating が 正確でない場合がある。\n",
    "        - rating が 0 だと、未評価なのか不支持なのかが曖昧。\n",
    "        - 自分はその商品が嫌いだが、他人のために買って上げた場合\n",
    "        - TV show の　recommend において、TV をつけっぱなしで寝てしまって、見ていないのに、再生時間が長い場合 etc\n",
    "    \n",
    "上述の SVD では explicit のみにしか対応していないので、 cold-start 問題に直面する可能性がある。\n",
    "    \n",
    "### SVD++\n",
    "\n",
    "- SVD の implicit data に対応した version。\n",
    "    - つまり、より多くのデータを扱えるので、一般的に SVD より精度が高くなる。([Hu et al. 2008](http://yifanhu.net/PUB/cf.pdf))\n",
    "- confidencの導入\n",
    "    - implicit data では rating が正確でないことがあるが、rating の値が高ければ高いほど、その rating は信用できると仮定をおいた。\n",
    "    - そして、その信用度=confidenceを 各rating の重みとし、より confidence の高い rating の誤差が、より小さくなるように学習する。\n",
    "- 最適化に解析解を用いることで計算量を抑えた。\n",
    "    - explicit data に対し、 data 数が多くなった。\n",
    "    - SVD では通常のSGDではなく、ALSを用いているので並列計算ができず遅い。\n",
    "    - そこで、ALSような数値的解法ではなく、解析的に局所最適化を繰り返すことで、計算量を減らした。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
