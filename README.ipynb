{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens 100K recommendation\n",
    "MovieLens 100K のデータセットに対し、 \n",
    "recommendation のアルゴリズムの1つ、 SVD\n",
    "を実装した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVDアルゴリズムの説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recommedation アルゴリズムの概要\n",
    "\n",
    "- 背景: 最近は情報過多社会。ユーザーにとって最適な商品（アイテム）の情報を探すのは大変。\n",
    "- 目的: そこで各ユーザーが好む最適な商品を、全ての商品から選出する必要がある。\n",
    "- 入力: ユーザーの行動履歴・評価 | アイテムの特徴 etc\n",
    "- 出力: ユーザーの評価が高い・選ぶであろうアイテム | 似たようなアイテム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recommedation アルゴリズムの分類\n",
    "\n",
    "- **CF Collaborative Filetering**\n",
    "    - memoery-based | Nearest Neighbor\n",
    "        - user-user | user-based\n",
    "        - item-item | item-based\n",
    "    - **model-based**\n",
    "        - **MF Matrix Factorization**\n",
    "            - SVD\n",
    "            - SVD++\n",
    "            - NMF\n",
    "        - clustering | regression | 確率モデル | topic model | Bayesean Network model | restricted Boltzmann machine | time series model\n",
    "- Content-based\n",
    "- Hybrid = CF + Content(|Demogarphic)\n",
    "    - FM\n",
    "    - VBPR\n",
    "\n",
    "今回は、 CF > model-based > MF > SVD を実装した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF vs Content-based\n",
    "- **CF**\n",
    "    - 入力: あるユーザーによる 商品のrating, 商品の購買・閲覧履歴 (e.g. 購入した服の5段階☆評価、ある服のページの閲覧、購入入したかしないか）\n",
    "    - 出力: ユーザーの評価が高い・買うであろうアイテム (e.g. )\n",
    "- Content-based\n",
    "    - 入力: アイテムの特徴 (e.g. 服の画像) \n",
    "    - 出力: 似たようなアイテム (e.g. 見た目が似たような服)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memory-based vs model-based\n",
    "\n",
    "CF では、下のFig.1のような　**(ユーザー数) x (アイテム数) の形の user-item matrix** をデータとして扱う。\n",
    "また、この行列は **rating matrix** とも言う。\n",
    "\n",
    "![](https://i.imgur.com/bmW79NS.png)\n",
    "\n",
    "Fig.1: user-item matrix rating\n",
    "\n",
    "行がuser, 列がitem　を表し、\n",
    "行列の各要素が、ある user による、ある item の 評価値である。\n",
    "\n",
    "行列の要素は **1~5段階評価** などがよく使われるが、\n",
    "評価ではなく、そのitemページの閲覧や、そのitemの購入をしたかしないか\n",
    "の **バイナリ（0/1）** でもよい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memory-based\n",
    "\n",
    "memory-based は、各行|列を user|item を表すベクトルとしてとらえる。\n",
    "そして、**ベクトル間の内積(cosine)**などで、 user|item 間の類似度を計算し、\n",
    "特定の user に対し、オススメの item を recommend する。\n",
    "\n",
    "**user-based** だと、user ベクトルの類似度を計算し、\n",
    "推薦をしたい user A が、まだ購入していない item のうち、\n",
    "A と似ている user B, C が高評価しているアイテムを推薦する。\n",
    "\n",
    "**item-based** では、 item ベクトルの類似度を計算し、\n",
    "A が高評価している item と似ている item を推薦する。\n",
    "\n",
    "欠点:\n",
    "- user-item matrix は sparse (0ばかり) であることが多く、良い精度で recommend できない。\n",
    "- recommendation 時に毎回、類似度を計算しなくてはならないので、 recommedation に時間がかかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model-based\n",
    "\n",
    "user-item matrix をそのまま推薦に用いるのではなく、\n",
    "一度、 **統計モデル** を学習させてから、推薦する手法。\n",
    "\n",
    "memory-based の欠点に対応している。\n",
    "- user による評価値の推定 → sparse 性への対応\n",
    "- 学習に時間がかかるが、一度学習してしまえば、推薦時間は短い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF Matrix Factorization\n",
    "user-item matrix における各 user|item ベクトルを\n",
    "潜在的な特徴量での表現に変換し、欠損している評価値を推定する手法。\n",
    "\n",
    "具体的には、 user-item matrix R の形が $m \\times n$ だとし、\n",
    "user u による item i の評価値を $r_{u,i}$ とすると、\n",
    "user u 、 item i を表す特徴量ベクトルは、\n",
    "\n",
    "$\\boldsymbol{r_u} = (r_{u1}, r_{u2}, ..., r_{un})^T$\n",
    "\n",
    "shape: (n, 1)\n",
    "\n",
    "$\\boldsymbol{r_i} = (r_{1i}, r_{2i}, ..., r_{mi})$\n",
    "\n",
    "shape: (1, m)\n",
    "\n",
    "で表せる。\n",
    "これらのベクトルを、$f$ （任意）次元の特徴量で表現し、\n",
    "それぞれを **user|item factor** とする。\n",
    "\n",
    "$\\boldsymbol{x_u} = (x_{u1}, x_{u2}, ..., x_{uf})$\n",
    "\n",
    "$\\boldsymbol{y_i} = (y_{i1}, y_{i2}, ..., y_{if})$\n",
    "\n",
    "これらを user|item ごとに縦に並べた行列を $X, Y$ とすると、 shape は、\n",
    "\n",
    "- X: (m, f)\n",
    "- Y: (n, f)\n",
    "\n",
    "となる。\n",
    "\n",
    "ここで、真のR (欠損値がないもの) は、\n",
    "X, Yの積で表されると仮定する。\n",
    "すなわち、\n",
    "\n",
    "$R \\approx XY^T$\n",
    "\n",
    "となる。\n",
    "\n",
    "この仮定を置く理由は、以下の直観的な背景からである。\n",
    "\n",
    "user および item は、 f 個の潜在的な特徴量を持っていると考える。\n",
    "たとえば、\n",
    "\n",
    "- user ベクトルの視点: この user が SF をどれくらい好きかを表す数値\n",
    "- item ベクトルの視点: この movie がどれくらい、 SF に当てはまるかの数値\n",
    "\n",
    "などが潜在的な特徴量として考えられる。\n",
    "\n",
    "userの好みのジャンルとitemのジャンルが近ければ、\n",
    "そのuserによる、そのitemの評価は高くなることが直観的に考えられる。\n",
    "\n",
    "また、userの潜在特徴ベクトルと、itemの潜在特徴ベクトルの内積は\n",
    "両ベクトルが似ているほど高い値を示す。\n",
    "つまり、先の、 ジャンルの好み と 評価値 の関係は、\n",
    "この 潜在特徴ベクトル と その内積の値 の関係ににている。\n",
    "なので、評価値は、各user、itemの潜在特徴ベクトルの内積で表せると仮定する。\n",
    "\n",
    "$r_{u,j} \\approx \\boldsymbol{x_u}\\boldsymbol{y_i}^T$\n",
    "\n",
    "これを行列でまとめて表現すると、先ほどの仮定に一致する。\n",
    "\n",
    "$R \\approx XY^T$\n",
    "\n",
    "また、この仮定は $R$ を\n",
    "2つの行列 $X, Y$ に分解しているので、\n",
    "行列分解 Matrix Factorizationとよぶ。\n",
    "\n",
    "k は通常、 user 数 m、item 数 n よりも少なくする。\n",
    "そうすることで、 sparse だった R を、\n",
    "より dense な X, Y で表現できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "\n",
    "MF のアルゴリズムの代表の1つとして、\n",
    "**SVD Singular Value Decomposition** があり、\n",
    "今回はこれを実装した。\n",
    "通常の数学の SVD では、 3つの行列に分解するが、\n",
    "MF 用に 2つの行列に分解する点で異なる。\n",
    "\n",
    "R の近似 $XY^T$ が、\n",
    "真の $R$ に近づけばいいので、\n",
    "これらの誤差を目的関数とする最小化問題を解けば良い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化手法\n",
    "上述の最適化問題を解く解法は以下の 2種類が代表的である。\n",
    "\n",
    "- **SGD Stochastic Gradient Descent** (MF専用で少し特殊)\n",
    "    - 数値的解法\n",
    "    - 利点: 評価済のみを計算、 sparse な行列に強い\n",
    "    - 欠点： 並列計算ができない\n",
    "- ALS Alternative Least Square\n",
    "    - 解析的解法\n",
    "    - 利点: 並列計算が得意、データ数が多い|dense な行列に強い\n",
    "    - 欠点: sparse な行列だと精度が良くない\n",
    "\n",
    "後述するが、今回のような rating data は explicit data といい、 \n",
    "行動履歴などのデータ (implicit) と違い、\n",
    "自動でたまらず、**行列が sparse** であることが多い。\n",
    "\n",
    "なので、今回、両方を実装したが、 SGD のほうが精度が良かった。\n",
    "説明においては、 **SGD** に焦点を当てる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD (MF専用)\n",
    "ALSに対し、SGDでは与えられた (欠損していない) \n",
    "評価値のみの誤差を使って最適化を行う。\n",
    "式で表すと、\n",
    "\n",
    "$\n",
    "min. \\sum_{u,i \\in \\{(u,i)|r_{u,i} \\neq 0\\}}(r_{u,i}-x_u y_i^T)^2 \n",
    "+ \\lambda(\\|x_u\\|^2 + \\|y_i\\|^2)\n",
    "$\n",
    "\n",
    "なお、学習パラメータは $X,Y$ であり、 \n",
    "$\\lambda$ は過学習を防ぐ正則化項の係数である。\n",
    "\n",
    "上記の目的関数の勾配を用いて、パラメータ $X, Y$ を update していく。\n",
    "更新式は以下。\n",
    "\n",
    "$e_{u,i} = (r_{ui} - x_u y_i^T)$\n",
    "\n",
    "$x_u \\leftarrow x_u - \\eta (- e_{u,i}y_i + \\lambda x_u)$\n",
    "\n",
    "$y_i \\leftarrow y_i - \\eta (- e_{u,i}x_u + \\lambda y_i)$\n",
    "\n",
    "- $e$ : 予測誤差\n",
    "- $\\eta$ : learning rateであり、後の括弧の中が目的関数の勾配である。\n",
    "\n",
    "各、評価済みの user, item の組 $(u,i)$ について\n",
    "この update を1回ずつ行っていく。\n",
    "\n",
    "また、すべての組についての更新が終わったら、これを1epochとし、\n",
    "学習時の引数として指定したepoch回数分、これを繰り返す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、今回は、学習パラメタに bias を追加した。\n",
    "\n",
    "$R \\approx XY^T + b^u + b^i + b$\n",
    "\n",
    "- $b^u = (b^u_1, b^u_2, ..., b^u_m)$\n",
    "    - shape: (m,1)\n",
    "- $b^i = (b^i_1, b^i_2, ..., b^i_n)^T$\n",
    "    - shape: (1,n)\n",
    "- $b = mean(R_{\\neq 0})$ (固定)\n",
    "\n",
    "で近似する。\n",
    "ただし、shapeにおいて長さが1となっている次元は、\n",
    "最大数のものに合わせるようにconcatenateする\n",
    "(e.g. (m,1)→(m,n)、axis=1の方向に同じベクトルを並べる。)\n",
    "\n",
    "bias を導入することで、\n",
    "辛口|甘口 user や、\n",
    "大人気|不人気 item による評価の偏りを考慮できる。\n",
    "\n",
    "たとえば、辛口でれば、user-bias のその user の要素は負の値をとり、\n",
    "その user の評価が全 item において低くなるように調整できる。\n",
    "\n",
    "上述の説明では、biasを加えると、SVDの本質がわかりにくくなるため、あえて省いた。\n",
    "目的関数も、勾配の式も、導出の方法は上述同様。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 評価\n",
    "MovieLensの trainting data u1.base、test data u1.test において、\n",
    "u1.baseで学習させ、u1.testで評価した。\n",
    "\n",
    "評価指標は直観的にわかりやすい RMSE Root Mean Squared Error を用いた。\n",
    "評価値が1であれば、各予測評価値が真の観測評価値よりも平均して1ほどずれている\n",
    "と考えればよい。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVDの改善点\n",
    "\n",
    "### explicit vs implicit data\n",
    "\n",
    "- **explicit data**: user に恣意的に行ってもらった rating\n",
    "    - e.g. 今回の movielens のような5段階で item を rating してもらったデータ\n",
    "    - 短所: user に rating してもらうので、 user に負担がかかり、データを集めにくい。 data を集められない → recommend できない → user が集まらない → data が集まらない → ... という悪循環に陥る可能性がある。 （cold-start problem)\n",
    "- **implicit data**\n",
    "    - e.g. 購入回数、動画の再生時間、ページ閲覧回数などの行動履歴\n",
    "    - 長所: 簡単に集められる。\n",
    "    - 短所: rating が 正確でない場合がある。\n",
    "        - rating が 0 だと、未評価なのか不支持なのかが曖昧。\n",
    "        - 自分はその商品が嫌いだが、他人のために買って上げた場合\n",
    "        - TV show の　recommend において、TV をつけっぱなしで寝てしまって、見ていないのに、再生時間が長い場合 etc\n",
    "    \n",
    "上述の SVD では explicit のみにしか対応していないので、 cold-start 問題に直面する可能性がある。\n",
    "\n",
    "なので、改善策として、以下の2つのアプローチが考えられる。\n",
    "- **implicit data** を用いる。\n",
    "- **hybrid** (CF + content-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD++\n",
    "\n",
    "- SVD の **implicit data に対応** した version。\n",
    "    - explicit より多くのデータを扱えるので、一般的に SVD より **精度が高く** なる。([Hu et al. 2008](http://yifanhu.net/PUB/cf.pdf))\n",
    "- confidencの導入\n",
    "    - implicit data では **rating が正確でない** ことがあるが、rating の値が高ければ高いほど、その rating は信用できると仮定をおいた。\n",
    "    - そして、その信用度=confidence で **各 rating の重み付け** をし、より confidence の高い rating の誤差が、より小さくなるように学習する。\n",
    "- ALS を用いた計算量の削減\n",
    "    - explicit data に対し、 data 数が多くなる。\n",
    "    - SVD では通常のSGDではなく並列計算ができないので、遅い。\n",
    "    - そこで、SGDような数値的解法ではなく、解析的に局所最適化を繰り返すALS(Alternative Least Square)を用いることで、計算量を減らした。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VBPR: Visual Bayesian Presonalized Ranking\n",
    "- MF に CNN による画像特徴量を加えて、 rating matrix を予測するモデル([He et al. 2015](https://arxiv.org/pdf/1510.01784.pdf))\n",
    "- さらに cold-start に強い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
